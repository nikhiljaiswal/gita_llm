{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c73041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import streamlit as st\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bc5395-0d8b-4c0f-b00d-d3337c6792bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import  ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# A ConversationalRetrievalChain is similar to a RetrievalQAChain, except that the ConversationalRetrievalChain allows for passing in of a chat history which can be used to allow for follow up questions.\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638766f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "#उपकरण को वाईफ़ाई से कनेक्ट करने के लिए कौन सी फ़्रीक्वेंसी राउटर समर्थित है?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "883193f4-c2eb-401a-bc1c-90fa5e641607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading PDF, DOCX and TXT files as LangChain Documents\n",
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "\n",
    "    if extension == '.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    elif extension == '.txt':\n",
    "        from langchain.document_loaders import TextLoader\n",
    "        loader = TextLoader(file, encoding='utf8')\n",
    "    else:\n",
    "        print('Document format is not supported!')\n",
    "        return None\n",
    "\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1499be04-206f-450b-919d-be918dbc254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data in chunks\n",
    "def chunk_data(data, chunk_size=256, chunk_overlap=0):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# create embeddings using OpenAIEmbeddings() and save them in a Chroma vector store\n",
    "def create_embeddings(chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = Chroma.from_documents(chunks, embeddings)\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def3770f-8804-4740-a85e-85fa49d2333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate embedding cost using tiktoken\n",
    "def calculate_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    # print(f'Total Tokens: {total_tokens}')\n",
    "    # print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.0004:.6f}')\n",
    "    return total_tokens, total_tokens / 1000 * 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58bd230a-05c5-4215-a32d-4875a93e0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q, k=3):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "    answer = chain.run(q)\n",
    "    return answer\n",
    "\n",
    "def ask_with_memory(vector_store, question, chat_history=[], k=3):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "    \n",
    "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "    print('question: ',question)\n",
    "    print('chat_history: ',chat_history)\n",
    "    result = crc({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    \n",
    "    return result['answer'], chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d9c77d7-e814-454a-9c00-642a589a014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: 512, Chunks: 279\n",
      "Embedding cost: $0.0098\n"
     ]
    }
   ],
   "source": [
    "file_name=\"C://Users//nikhil.jaiswal//workspace//learning//langchain//Resources//Notebooks//data//MFL71521482_lower.txt\"\n",
    "\n",
    "chunk_size = 512\n",
    "\n",
    "data = load_document(file_name)\n",
    "chunks = chunk_data(data, chunk_size=chunk_size)\n",
    "print(f'Chunk size: {chunk_size}, Chunks: {len(chunks)}')\n",
    "\n",
    "tokens, embedding_cost = calculate_embedding_cost(chunks)\n",
    "print(f'Embedding cost: ${embedding_cost:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e43c19-b798-4019-be7f-2c067d5b8f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the embeddings and returning the Chroma vector store\n",
    "vector_store = create_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b17753d1-4102-408c-bb59-040f813b3e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight of this product is 154.3 lb (70 kg).\n"
     ]
    }
   ],
   "source": [
    "q = 'what is the weight of this product?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8cef8f-d3de-4030-baba-56885a9f2851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3a23f-4993-4d37-8a96-0e6cc0c872a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a7c85-d516-489d-bbee-db89bd77b16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eab3e4-2e62-4380-a688-0ebb027c7a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d392bde-0039-4bdd-8e0c-e4946d45568e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14d9ba-9358-4da7-9cff-14522ca61fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524b191-f63c-48de-a01c-bacc51906727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83b4b44-aae4-485e-9663-5d5bd8dc2dbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create the chain\u001b[39;00m\n\u001b[0;32m      5\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mvector_store\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m, search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m})\n\u001b[0;32m      8\u001b[0m chain \u001b[38;5;241m=\u001b[39m ConversationalRetrievalChain\u001b[38;5;241m.\u001b[39mfrom_llm(\n\u001b[0;32m      9\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm, \n\u001b[0;32m     10\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mretriever,\n\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector_store' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Create the chain\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, \n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a8086e-8f26-4452-95e9-c46b211642e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q, k=3):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "    answer = chain.run(q)\n",
    "    return answer\n",
    "\n",
    "def ask_with_memory(vector_store, question, chat_history=[], k=3):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "    \n",
    "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "    print('question: ',question)\n",
    "    print('chat_history: ',chat_history)\n",
    "    result = crc({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    \n",
    "    return result['answer'], chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd2ee819-a817-46eb-9e7b-38f738f7f0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  At what voltage should we connect the washing machine?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  At what voltage should we connect the washing machine?\n",
      "chat_history:  []\n",
      "\n",
      " Answer: The washing machine should be plugged into a 120V power outlet.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  What is the weight of this product\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What is the weight of this product\n",
      "chat_history:  [('At what voltage should we connect the washing machine?', 'The washing machine should be plugged into a 120V power outlet.')]\n",
      "\n",
      " Answer: The weight of the washing machine is 154.3 lb (70 kg).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  can you  repeat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  can you  repeat\n",
      "chat_history:  [('At what voltage should we connect the washing machine?', 'The washing machine should be plugged into a 120V power outlet.'), ('What is the weight of this product', 'The weight of the washing machine is 154.3 lb (70 kg).')]\n",
      "\n",
      " Answer: The weight of the washing machine is 154.3 lb (70 kg).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  and voltage?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  and voltage?\n",
      "chat_history:  [('At what voltage should we connect the washing machine?', 'The washing machine should be plugged into a 120V power outlet.'), ('What is the weight of this product', 'The weight of the washing machine is 154.3 lb (70 kg).'), ('can you  repeat', 'The weight of the washing machine is 154.3 lb (70 kg).')]\n",
      "\n",
      " Answer: The washing machine should be connected to a 120V power supply.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  what are features of control panel?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  what are features of control panel?\n",
      "chat_history:  [('At what voltage should we connect the washing machine?', 'The washing machine should be plugged into a 120V power outlet.'), ('What is the weight of this product', 'The weight of the washing machine is 154.3 lb (70 kg).'), ('can you  repeat', 'The weight of the washing machine is 154.3 lb (70 kg).'), ('and voltage?', 'The washing machine should be connected to a 120V power supply.')]\n",
      "\n",
      " Answer: The features of the control panel include locking/unlocking the controls, displaying the remaining time and cl (child lock) during the wash cycle, and activating/deactivating the function by pressing and holding the delay wash and add item buttons simultaneously for 3 seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  what are the terms and conditions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  what are the terms and conditions\n",
      "chat_history:  [('At what voltage should we connect the washing machine?', 'The washing machine should be plugged into a 120V power outlet.'), ('What is the weight of this product', 'The weight of the washing machine is 154.3 lb (70 kg).'), ('can you  repeat', 'The weight of the washing machine is 154.3 lb (70 kg).'), ('and voltage?', 'The washing machine should be connected to a 120V power supply.'), ('what are features of control panel?', 'The features of the control panel include locking/unlocking the controls, displaying the remaining time and cl (child lock) during the wash cycle, and activating/deactivating the function by pressing and holding the delay wash and add item buttons simultaneously for 3 seconds.')]\n",
      "\n",
      " Answer: The terms and conditions mentioned in the provided context refer to the terms and conditions of a limited warranty. Unfortunately, the specific details of the terms and conditions are not provided in the given context.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m chat_history\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     q\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuery: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     answer,chat_history \u001b[38;5;241m=\u001b[39m ask_with_memory(vector_store, q,chat_history\u001b[38;5;241m=\u001b[39mchat_history)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Answer:\u001b[39m\u001b[38;5;124m'\u001b[39m,answer)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\langchain_poc\\lib\\site-packages\\ipykernel\\kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\langchain_poc\\lib\\site-packages\\ipykernel\\kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "chat_history=[]\n",
    "\n",
    "while True:\n",
    "    q=input('Query: ')\n",
    "    answer,chat_history = ask_with_memory(vector_store, q,chat_history=chat_history)\n",
    "    print('\\n Answer:',answer)\n",
    "    #chat_history.append((q, answer))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02bab55e-f0c4-45cf-9b79-a6838c97ac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What will happen if we use lot of detergent?\n",
      "chat_history:  []\n",
      "Using too much detergent can lead to several issues:\n",
      "\n",
      "1. Oversudsing: Excessive detergent can create too many suds, which can interfere with the washing process. This can result in poor cleaning performance and may even cause the washer to overflow.\n",
      "\n",
      "2. Poor rinsing: Excess detergent can be difficult to rinse out completely, leaving behind residue on your clothes. This can make them feel stiff, look dull, and contribute to odors.\n",
      "\n",
      "3. Detergent buildup in clothing: If too much detergent is used regularly, it can build up in the fabric fibers over time. This can make clothes feel stiff, look dingy, and reduce their lifespan.\n",
      "\n",
      "4. Residue buildup in the washer: Excessive detergent can also accumulate in the washer itself, leading to a buildup of residue. This residue can cause unpleasant odors and may even affect the performance of the machine.\n",
      "\n",
      "To avoid these issues, it is important to follow the manufacturer's recommendations for detergent usage and use the appropriate amount for your load size and water hardness.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chat_history=[]\n",
    "q = 'What will happen if we use lot of detergent?'\n",
    "answer,chat_history = ask_with_memory(vector_store, q,chat_history=chat_history)\n",
    "print(answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1938bc37-fb6a-47a2-af70-6d3662165645",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append((q, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e48fad01-5aab-4ca9-9faa-9b0eb8381a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  can you repeat?\n",
      "chat_history:  [('What will happen if we use lot of detergent?', \"Using too much detergent can lead to several issues:\\n\\n1. Oversudsing: Excessive detergent can create too many suds, which can interfere with the washing process. This can result in poor cleaning performance and may even cause the washer to overflow.\\n\\n2. Poor rinsing: Excess detergent can be difficult to rinse out completely, leaving behind residue on your clothes. This can make them feel stiff, look dull, and contribute to odors.\\n\\n3. Detergent buildup in clothing: If too much detergent is used regularly, it can build up in the fabric fibers over time. This can make clothes feel stiff, look dingy, and reduce their lifespan.\\n\\n4. Residue buildup in the washer: Excessive detergent can also accumulate in the washer itself, leading to a buildup of residue. This residue can cause unpleasant odors and may even affect the performance of the machine.\\n\\nTo avoid these issues, it is important to follow the manufacturer's recommendations for detergent usage and use the appropriate amount for your load size and water hardness.\"), ('What will happen if we use lot of detergent?', \"Using too much detergent can lead to several issues:\\n\\n1. Oversudsing: Excessive detergent can create too many suds, which can interfere with the washing process. This can result in poor cleaning performance and may even cause the washer to overflow.\\n\\n2. Poor rinsing: Excess detergent can be difficult to rinse out completely, leaving behind residue on your clothes. This can make them feel stiff, look dull, and contribute to odors.\\n\\n3. Detergent buildup in clothing: If too much detergent is used regularly, it can build up in the fabric fibers over time. This can make clothes feel stiff, look dingy, and reduce their lifespan.\\n\\n4. Residue buildup in the washer: Excessive detergent can also accumulate in the washer itself, leading to a buildup of residue. This residue can cause unpleasant odors and may even affect the performance of the machine.\\n\\nTo avoid these issues, it is important to follow the manufacturer's recommendations for detergent usage and use the appropriate amount for your load size and water hardness.\"), ('What you said?', 'I apologize for any confusion. Based on the provided context, it appears to be discussing the process of resolving a claim, action, dispute, or controversy between the user and LG. It suggests that if both parties cannot reach a resolution within 30 days, either party may proceed to file a claim for arbitration.')]\n",
      "Certainly! The context provided includes information about agreeing to a different location or telephonic arbitration, the meanings of warning and caution, the purpose of safety messages, and the process for filing a claim for arbitration if a dispute cannot be resolved within 30 days.\n"
     ]
    }
   ],
   "source": [
    "q = 'can you repeat?'\n",
    "answer,chat_history = ask_with_memory(vector_store, q,chat_history=chat_history)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3e03fb6-6d61-4dcd-9111-bc5a6a884c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for any confusion. The statement is discussing the options for resolving a claim, action, dispute, or controversy between the user and LG. It states that both parties can agree to either choose another location for arbitration or opt for telephonic arbitration. If the dispute cannot be resolved within 30 days, either party can proceed to file a claim for arbitration.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b74c8-47b4-4b0f-a98c-bdc4b68c8d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d39320-035f-4063-ae86-fbab6119fd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da354834-99e4-4a9f-887c-9b969683254d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What will happen if we use lot of detergent?',\n",
       "  \"Using too much detergent can lead to several issues:\\n\\n1. Oversudsing: Excessive detergent can create too many suds, which can interfere with the washing process. This can result in poor cleaning performance and may even cause the washer to overflow.\\n\\n2. Poor rinsing: Excess detergent can be difficult to rinse out completely, leaving behind residue on your clothes. This can make them feel stiff, look dull, and contribute to odors.\\n\\n3. Detergent buildup in clothing: If too much detergent is used regularly, it can build up in the fabric fibers over time. This can make clothes feel stiff, look dingy, and reduce their lifespan.\\n\\n4. Residue buildup in the washer: Excessive detergent can also accumulate in the washer itself, leading to a buildup of residue. This residue can cause unpleasant odors and may even affect the performance of the machine.\\n\\nTo avoid these issues, it is important to follow the manufacturer's recommendations for detergent usage and use the appropriate amount for your load size and water hardness.\")]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97991cdf-90a6-45dd-9656-706984bdfcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight of this product is 154.3 lb (70 kg).\n"
     ]
    }
   ],
   "source": [
    "q = 'what is the weight of this product?'\n",
    "answer,chat_history = ask_with_memory(vector_store, q,chat_history)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6cd286e-aed1-4d77-b4f4-4d5a5e91385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight of this product is 154.3 lb (70 kg).\n"
     ]
    }
   ],
   "source": [
    "q = 'what did you say'\n",
    "answer,chat_history = ask_with_memory(vector_store, q,chat_history)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01726d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate embedding cost using tiktoken\n",
    "def calculate_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    # print(f'Total Tokens: {total_tokens}')\n",
    "    # print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.0004:.6f}')\n",
    "    return total_tokens, total_tokens / 1000 * 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "774ef0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natsort\n",
      "  Obtaining dependency information for natsort from https://files.pythonhosted.org/packages/ef/82/7a9d0550484a62c6da82858ee9419f3dd1ccc9aa1c26a1e43da3ecd20b0d/natsort-8.4.0-py3-none-any.whl.metadata\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Using cached natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: natsort\n",
      "Successfully installed natsort-8.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d5196a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5522dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Obtaining dependency information for chromadb from https://files.pythonhosted.org/packages/5f/86/599e1482723dea206ad269aece4e4907f4a981840fcb6c731d39f79098ed/chromadb-0.4.5-py3-none-any.whl.metadata\n",
      "  Downloading chromadb-0.4.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.9 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from chromadb) (1.10.12)\n",
      "Collecting chroma-hnswlib==0.7.2 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.2-cp39-cp39-win_amd64.whl\n",
      "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
      "  Obtaining dependency information for fastapi<0.100.0,>=0.95.2 from https://files.pythonhosted.org/packages/73/eb/03b691afa0b5ffa1e93ed34f97ec1e7855c758efbdcfb16c209af0b0506b/fastapi-0.99.1-py3-none-any.whl.metadata\n",
      "  Downloading fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
      "  Obtaining dependency information for uvicorn[standard]>=0.18.3 from https://files.pythonhosted.org/packages/79/96/b0882a1c3f7ef3dd86879e041212ae5b62b4bd352320889231cc735a8e8f/uvicorn-0.23.2-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from chromadb) (1.25.1)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from chromadb) (4.7.1)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Obtaining dependency information for pulsar-client>=3.1.0 from https://files.pythonhosted.org/packages/16/41/916913948556521ee29c44a97d40b60df66dc0e6de09103552011663d10c/pulsar_client-3.2.0-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading pulsar_client-3.2.0-cp39-cp39-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/6a/fb/99bc0e75f3d23eab0dda640acaf23d0a3a68c3949a56ac5c25698eab4958/onnxruntime-1.15.1-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading onnxruntime-1.15.1-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from chromadb) (7.3.1)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/25/d4/592f53ce2f8dde8be5720851bd0ab71cc2e76c55978e4163ef1ab7e389bb/importlib_resources-6.0.1-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.0.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
      "  Obtaining dependency information for starlette<0.28.0,>=0.27.0 from https://files.pythonhosted.org/packages/58/f8/e2cca22387965584a409795913b774235752be4176d276714e15e1a58884/starlette-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: packaging in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.4)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from requests>=2.28->chromadb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from tqdm>=4.65.0->chromadb) (0.4.6)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.6)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Obtaining dependency information for httptools>=0.5.0 from https://files.pythonhosted.org/packages/2b/15/a48d8036bf6ed80201f41479df1813ad1e01b48284281edcbefd05c3a364/httptools-0.6.0-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading httptools-0.6.0-cp39-cp39-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-0.19.0-cp37-abi3-win_amd64.whl (270 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-11.0.3-cp39-cp39-win_amd64.whl (124 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from importlib-resources->chromadb) (3.16.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchain_poc\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.2)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Downloading chromadb-0.4.5-py3-none-any.whl (402 kB)\n",
      "   ---------------------------------------- 0.0/402.8 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/402.8 kB 960.0 kB/s eta 0:00:01\n",
      "   --- ----------------------------------- 41.0/402.8 kB 960.0 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 92.2/402.8 kB 655.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 143.4/402.8 kB 944.1 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 204.8/402.8 kB 958.4 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 276.5/402.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------- -------- 317.4/402.8 kB 981.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  399.4/402.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 402.8/402.8 kB 1.1 MB/s eta 0:00:00\n",
      "Using cached fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
      "Using cached onnxruntime-1.15.1-cp39-cp39-win_amd64.whl (6.7 MB)\n",
      "Using cached pulsar_client-3.2.0-cp39-cp39-win_amd64.whl (3.4 MB)\n",
      "Downloading importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
      "Using cached httptools-0.6.0-cp39-cp39-win_amd64.whl (147 kB)\n",
      "Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Using cached uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "Installing collected packages: tokenizers, pyreadline3, pypika, mpmath, monotonic, flatbuffers, websockets, sympy, python-dotenv, pulsar-client, importlib-resources, humanfriendly, httptools, h11, chroma-hnswlib, backoff, watchfiles, uvicorn, starlette, posthog, coloredlogs, onnxruntime, fastapi, chromadb\n",
      "Successfully installed backoff-2.2.1 chroma-hnswlib-0.7.2 chromadb-0.4.5 coloredlogs-15.0.1 fastapi-0.99.1 flatbuffers-23.5.26 h11-0.14.0 httptools-0.6.0 humanfriendly-10.0 importlib-resources-6.0.1 monotonic-1.6 mpmath-1.3.0 onnxruntime-1.15.1 posthog-3.0.1 pulsar-client-3.2.0 pypika-0.48.9 pyreadline3-3.4.1 python-dotenv-1.0.0 starlette-0.27.0 sympy-1.12 tokenizers-0.13.3 uvicorn-0.23.2 watchfiles-0.19.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc0bed16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e37514fa-6ad4-4b1b-be96-b1580de4a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "doc_dir = \"C://Users//nikhil.jaiswal//workspace//haystack_demo//data//MFL71521482\"\n",
    "fl=os.listdir(doc_dir)\n",
    "fl=natsorted(fl)\n",
    "op=[]\n",
    "\n",
    "for f in fl:\n",
    "    src=os.path.join(doc_dir,f)\n",
    "    ln=open(src, encoding=\"utf8\").readlines()\n",
    "    ln=[l.strip() for l in ln]\n",
    "    ln=[l for l in ln if l!='']\n",
    "    ln=ln[1:]\n",
    "    \n",
    "    for l in ln:\n",
    "        op.append(l.lower()+'\\n') \n",
    "    #print(ln)\n",
    "    op.append('\\n')\n",
    "    #op+=ln\n",
    "\n",
    "doc_dir = \"C://Users//nikhil.jaiswal//workspace//learning//langchain//Resources//Notebooks//data\"\n",
    "tgt=os.path.join(doc_dir,'MFL71521482_new_lower.txt')\n",
    "with open(tgt,'w',encoding=\"utf8\") as f:\n",
    "    for o in op:\n",
    "        f.write(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125961b-b4b4-4e6d-a3eb-b5b3c0e697d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178bca7-f30b-4239-bd16-3395a5f22fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "390e12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "fl=os.listdir(doc_dir)\n",
    "fl=natsorted(fl)\n",
    "op=[]\n",
    "\n",
    "for f in fl:\n",
    "    src=os.path.join(doc_dir,f)\n",
    "    ln=open(src, encoding=\"utf8\").readlines()\n",
    "    ln=[l.strip() for l in ln]\n",
    "    ln=[l for l in ln if l!='']\n",
    "    op+=ln\n",
    "\n",
    "doc_dir = \"C://Users//nikhil.jaiswal//workspace//learning//langchain//Resources//Notebooks//data\"\n",
    "tgt=os.path.join(doc_dir,'MFL71521482.txt')\n",
    "with open(tgt,'w',encoding=\"utf8\") as f:\n",
    "    for o in op:\n",
    "        f.write(o+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "871293d1-b0f9-47b2-80e6-9417eee4d0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top > IMPORTANT SAFETY INSTRUCTIONS > READ ALL INSTRUCTIONS BEFORE USE > Safety Messages'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79459acc-2516-4853-9903-d5483efbf184",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"C://Users//nikhil.jaiswal//workspace//learning//langchain//Resources//Notebooks//data//MFL71521482.txt\"\n",
    "\n",
    "new_file_name=\"C://Users//nikhil.jaiswal//workspace//learning//langchain//Resources//Notebooks//data//MFL71521482_lower.txt\"\n",
    "\n",
    "ln=open(file_name,encoding=\"utf8\").readlines()\n",
    "ln=[l.strip().lower() for l in ln] \n",
    "\n",
    "with open(new_file_name,'w',encoding=\"utf8\") as f:\n",
    "    for l in ln:\n",
    "        f.write(l+'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81824202",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_document' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC://Users//nikhil.jaiswal//workspace//learning//langchain//Resources//Notebooks//data//MFL71521482_lower.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[1;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_document\u001b[49m(file_name)\n\u001b[0;32m      6\u001b[0m chunks \u001b[38;5;241m=\u001b[39m chunk_data(data, chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChunk size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Chunks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_document' is not defined"
     ]
    }
   ],
   "source": [
    "file_name=\"C://Users//nikhil.jaiswal//workspace//learning//langchain//Resources//Notebooks//data//MFL71521482_lower.txt\"\n",
    "\n",
    "chunk_size = 512\n",
    "\n",
    "data = load_document(file_name)\n",
    "chunks = chunk_data(data, chunk_size=chunk_size)\n",
    "print(f'Chunk size: {chunk_size}, Chunks: {len(chunks)}')\n",
    "\n",
    "tokens, embedding_cost = calculate_embedding_cost(chunks)\n",
    "print(f'Embedding cost: ${embedding_cost:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d004a0-ccbc-48fa-859c-dc67b8e0a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"product specifications\\nmodel - wm1455h*a\\nelectrical requirements - 120 v~, 60 hz\\nmin. / max. water pressure - 20 psi - 120 psi (138 kpa - 827 kpa)\\ndimensions (width x height x depth) - 24'' x 33 1/2'' x 22 1/4'' (60 cm x 85 cm x 56.5 cm)\\nmaximum depth with door open - 43 1/4'' (110 cm)\\nnet weight - 154.3 lb (70 kg)\\nmax. spin speed - 1400 rpm\", metadata={'source': 'C://Users//nikhil.jaiswal//workspace//learning//langchain//Resources//Notebooks//data//MFL71521482_lower.txt'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e196e8f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# creating the embeddings and returning the Chroma vector store\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m create_embeddings(\u001b[43mchunks\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chunks' is not defined"
     ]
    }
   ],
   "source": [
    "# creating the embeddings and returning the Chroma vector store\n",
    "vector_store = create_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30b2a194-11c5-4be5-b1fd-ce29d0b7bc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight of this product is 154.3 lb (70 kg).\n"
     ]
    }
   ],
   "source": [
    "q = 'what is the weight of this product?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf1c7cd-a51d-449c-9d6f-fc2494f24062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using too much detergent can lead to several issues:\n",
      "\n",
      "1. Oversudsing: Excessive detergent can cause the washer to produce too many suds, which can lead to leaks and poor rinsing of clothes.\n",
      "\n",
      "2. Detergent buildup: Using more than the recommended amount can result in detergent residue building up on clothing, which can contribute to odors in the washer.\n",
      "\n",
      "3. Poor rinsing: Excess detergent can make it difficult for the washer to rinse clothes thoroughly, leaving behind soap residue that can make clothes feel stiff or sticky.\n",
      "\n",
      "4. Odor buildup: Detergent residue can accumulate in the washer over time, leading to unpleasant odors.\n",
      "\n",
      "To avoid these problems, it is important to follow the manufacturer's recommendations for the appropriate amount of detergent to use.\n"
     ]
    }
   ],
   "source": [
    "q = 'what will happen if we use lot of detergent?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd8d926e-d2a6-487d-8d05-9cc9a8258cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The liquid bleach compartment is used to add liquid chlorine bleach to the washer during the wash cycle.\n"
     ]
    }
   ],
   "source": [
    "q = 'What is the use of liquid bleach compartment?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f3abebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The liquid bleach compartment is used to add liquid chlorine bleach to the washer during the main wash cycle.\n"
     ]
    }
   ],
   "source": [
    "q = 'What is the use of liquid bleach compartment?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6d7fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not mention a specific \"temperature indicator.\" Therefore, it is not possible to determine when the temperature indicator turns on based on the given information.\n"
     ]
    }
   ],
   "source": [
    "q = 'When does temperature indicator turn on?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8f81d8-3ae6-40b2-a9db-ff28428421cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the laundry tub for draining, follow these steps:\n",
      "\n",
      "1. Clip the end of the drain hose into the elbow bracket.\n",
      "2. Make sure the water valves and drain are built into the wall.\n",
      "3. Fasten the drain hose to one of the water hoses using the provided tie strap. Ensure that the ribbed side of the tie strap is on the inside.\n",
      "4. Close the door of the washer.\n",
      "5. Press the power button to turn on the washer.\n",
      "6. Select the \"Tub Clean\" cycle.\n",
      "7. Press the start/pause button to begin the cycle.\n",
      "8. After the cycle ends, open the door of the washer.\n",
      "9. Allow the drum interior to dry completely.\n",
      "10. Make sure to engage the control lock feature if needed to prevent children from accidentally starting a wash cycle.\n"
     ]
    }
   ],
   "source": [
    "q = 'What are the steps of using the laundry tub for draining?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb0e3857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the laundry tub for draining, follow these steps:\n",
      "\n",
      "1. Clip the end of the drain hose into the elbow bracket.\n",
      "2. Make sure the water valves and drain are built into the wall.\n",
      "3. Fasten the drain hose to one of the water hoses using the provided tie strap. Ensure that the ribbed side of the tie strap is on the inside.\n",
      "4. Once the drain hose is securely attached, you can use the laundry tub to drain the water from the washer.\n",
      "\n",
      "Remember to always exercise caution and avoid reaching into the washer while the tub or drum is in motion. Before loading, unloading, or adding items, press the Start/Pause button and allow the tub or drum to come to a complete stop before reaching inside.\n"
     ]
    }
   ],
   "source": [
    "q = 'What are the steps of using the laundry tub for draining?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0d0c76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The appliance supports a 2.4 GHz router frequency for connecting to the Wi-Fi network.\n"
     ]
    }
   ],
   "source": [
    "q = 'What frequency router is supported for connecting the appliance to the wifi?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea15dd02-3734-48fb-9298-f84585ac503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IE error message typically indicates a problem with the water supply. It could be caused by water supply faucets not being fully open, kinked or crushed water inlet hoses, clogged water inlet filters, or low water supply pressure. To resolve the issue, you can try the following solutions:\n",
      "\n",
      "1. Make sure that the water faucets are fully open.\n",
      "2. Check the water inlet hoses to ensure they are not kinked, pinched, or crushed.\n",
      "3. Clean the water inlet filters.\n",
      "4. Verify that the water supply pressure to the faucet or house is not too low.\n",
      "\n",
      "If none of these solutions resolve the issue, it may be best to contact a service technician for further assistance.\n"
     ]
    }
   ],
   "source": [
    "q = 'IE error is coming on the display'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9770d69-8ded-4485-87de-ad3f3c4245f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IE error message typically indicates a problem with the water supply. It could be caused by water supply faucets not being fully open, kinked or crushed water inlet hoses, clogged water inlet filters, or low water supply pressure. To resolve the issue, you can try the following solutions:\n",
      "\n",
      "1. Make sure that the water faucets are fully open.\n",
      "2. Check the water inlet hoses to ensure they are not kinked, pinched, or crushed.\n",
      "3. Clean the water inlet filters.\n",
      "4. Verify that the water supply pressure to the faucet or house is not too low.\n",
      "\n",
      "If none of these solutions resolve the issue, it may be best to contact a service technician for further assistance.\n"
     ]
    }
   ],
   "source": [
    "q = 'IE error is coming on the display'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01f73778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IE error message indicates that there is an issue with the water inlet. There are several possible causes for this error, including:\n",
      "\n",
      "1. Water supply faucets are not fully open: Make sure that the water faucets connected to the washer are fully open.\n",
      "\n",
      "2. Water inlet hoses are kinked, pinched, or crushed: Check the hoses behind or under the washer to ensure they are not kinked, pinched, or crushed. Be careful when moving the washer during cleaning or maintenance.\n",
      "\n",
      "3. Water inlet filters are clogged: Clean the inlet filters. You can refer to the maintenance instructions for guidance on how to clean them.\n",
      "\n",
      "4. Water supply pressure to the faucet or house is too low: If the water pressure in your house is low, it may cause the IE error. You may need to contact a plumber to check and adjust the water supply pressure.\n",
      "\n",
      "Please check these possible causes and solutions to resolve the IE error. If the issue persists, it may be best to contact the manufacturer or a professional technician for further assistance.\n"
     ]
    }
   ],
   "source": [
    "q = 'ie error is coming on the display'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13b05ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To resolve the DE (DOOR OPEN ERROR) on a washer, follow these steps:\n",
      "\n",
      "1. Close and secure the door properly. Make sure it is fully closed and latched.\n",
      "\n",
      "2. If the error message continues to appear, unplug the power cord from the outlet.\n",
      "\n",
      "3. Contact the manufacturer or a service technician for further assistance. They will be able to diagnose and fix any issues with the door sensor or latch mechanism.\n"
     ]
    }
   ],
   "source": [
    "q = 'How to resolve DE error'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be400deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The terms and conditions mentioned in the provided context are regarding the arbitration provision in the Limited Warranty. It states that disputes between the user and LG must be resolved through binding arbitration instead of court, unless the laws of the user's province or territory do not permit arbitration or if the user chooses to opt out. In arbitration, class actions and jury trials are not permitted. The procedure for resolving disputes through arbitration is detailed in the section titled \"Procedure for Resolving Disputes.\"\n"
     ]
    }
   ],
   "source": [
    "q = 'What are the terms and conditions'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d42fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The warranty does not cover noises associated with normal operation or failure to follow instructions, as well as operating the unit in an unsuitable environment. It also does not cover costs and expenses associated with excluded circumstances.\n"
     ]
    }
   ],
   "source": [
    "q = 'please tell me what is not covered under warranty period '\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d7d87ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, according to the provided context, it is recommended to sort articles by color and wash dark clothes separately from light colors or whites. Mixing dark clothes with light clothes can result in dye transfer or discoloration of the lighter clothes.\n"
     ]
    }
   ],
   "source": [
    "q = 'Yes, you can wash dark and light color clothes together.'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d9c9eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To install the LG ThinQ app, you can search for it on the Google Play Store or Apple App Store on your smartphone. Once you find the app, follow the instructions to download and install it on your device.\n"
     ]
    }
   ],
   "source": [
    "q = 'how can i install the lg thinq app?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a37bc1ca-d7c7-4ed3-b3d1-88f332fa9838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what should be the router frequency in order to connect with appliance?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st='What should be the router frequency in order to connect with appliance?'\n",
    "st.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "498711e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Using cached streamlit-1.25.0-py2.py3-none-any.whl (8.1 MB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.0.1-py3-none-any.whl (471 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (8.1.6)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (6.7.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (1.25.0)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (1.5.3)\n",
      "Collecting pillow<10,>=7.1.0 (from streamlit)\n",
      "  Using cached Pillow-9.5.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (4.23.4)\n",
      "Collecting pyarrow>=6.0 (from streamlit)\n",
      "  Using cached pyarrow-12.0.1-cp39-cp39-win_amd64.whl (21.5 MB)\n",
      "Collecting pympler<2,>=0.9 (from streamlit)\n",
      "  Using cached Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.18 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Downloading rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "                                              0.0/239.7 kB ? eta -:--:--\n",
      "                                              0.0/239.7 kB ? eta -:--:--\n",
      "     -                                        10.2/239.7 kB ? eta -:--:--\n",
      "     ----                                  30.7/239.7 kB 330.3 kB/s eta 0:00:01\n",
      "     ------                                41.0/239.7 kB 245.8 kB/s eta 0:00:01\n",
      "     -----------------------------        194.6/239.7 kB 908.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ 239.7/239.7 kB 980.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (8.2.2)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (4.6.3)\n",
      "Collecting tzlocal<5,>=1.1 (from streamlit)\n",
      "  Using cached tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
      "Collecting validators<1,>=0.2 (from streamlit)\n",
      "  Using cached validators-0.20.0-py3-none-any.whl\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
      "Collecting pydeck<1,>=0.8 (from streamlit)\n",
      "  Using cached pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from streamlit) (6.3.2)\n",
      "Collecting watchdog>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-3.0.0-py3-none-win_amd64.whl (82 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit)\n",
      "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from requests<3,>=2.18->streamlit) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from requests<3,>=2.18->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from requests<3,>=2.18->streamlit) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from requests<3,>=2.18->streamlit) (2023.5.7)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Collecting pytz-deprecation-shim (from tzlocal<5,>=1.1->streamlit)\n",
      "  Using cached pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tzdata (from tzlocal<5,>=1.1->streamlit)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from validators<1,>=0.2->streamlit) (5.1.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\nikhil.jaiswal\\anaconda3\\envs\\langchn\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: watchdog, validators, tzdata, toolz, toml, smmap, pympler, pyarrow, pillow, mdurl, cachetools, blinker, pytz-deprecation-shim, pydeck, markdown-it-py, gitdb, tzlocal, rich, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.0.1 blinker-1.6.2 cachetools-5.3.1 gitdb-4.0.10 gitpython-3.1.32 markdown-it-py-3.0.0 mdurl-0.1.2 pillow-9.5.0 pyarrow-12.0.1 pydeck-0.8.0 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 rich-13.5.2 smmap-5.0.0 streamlit-1.25.0 toml-0.10.2 toolz-0.12.0 tzdata-2023.3 tzlocal-4.3.1 validators-0.20.0 watchdog-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clear the chat history from streamlit session state\n",
    "def clear_history():\n",
    "    if 'history' in st.session_state:\n",
    "        del st.session_state['history']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eddca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import  ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "system_template_lang_detection = \"I want you act as a language detector. I will input a sentence in any language and you will answer me in which language the sentence I wrote is in. Do not write any explanations or other words, just reply with the language name\"\n",
    "human_template_lang_detection = \"Sentence: {source_sentence}\"\n",
    "\n",
    "system_prompt_lang_detection = SystemMessagePromptTemplate.from_template(system_template_lang_detection)\n",
    "human_prompt_lang_detection = HumanMessagePromptTemplate.from_template(human_template_lang_detection, \n",
    "                                                                       input_variables=[\"source_sentence\"])\n",
    "lang_detection_prompt = ChatPromptTemplate.from_messages([system_prompt_lang_detection, human_prompt_lang_detection])\n",
    "lang_detection_chain = LLMChain(llm=llm, prompt=lang_detection_prompt, output_key=\"source_language\")\n",
    "\n",
    "\n",
    "\n",
    "system_template_translation = \"You are a good Translator. Translate this sentence from {source_language} to English. Do not write any other words, just reply with the translated sentence.\"\n",
    "human_template_translation = \"Sentence: {source_sentence}\"\n",
    "\n",
    "system_prompt_translation = SystemMessagePromptTemplate.from_template(system_template_translation, input_variables=[\"source_language\"])\n",
    "human_prompt_translation = HumanMessagePromptTemplate.from_template(human_template_translation, input_variables=[\"source_sentence\"])\n",
    "translation_prompt = ChatPromptTemplate.from_messages([system_prompt_translation, human_prompt_translation])\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt, output_key=\"target_sentence\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_chain = SequentialChain(chains=[lang_detection_chain, translation_chain], \n",
    "                                      input_variables=[\"source_sentence\"],\n",
    "                                      output_variables=[\"source_language\", \"source_sentence\"],verbose=True)\n",
    "\n",
    "\n",
    "overall_chain({\"source_sentence\":\"उपकरण को वाईफ़ाई से कनेक्ट करने के लिए कौन सी फ़्रीक्वेंसी राउटर समर्थित है?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb1c3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which frequency router supports connecting the device via Wi-Fi?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import  ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "system_template_lang_detection = \"I want you act as a language detector. I will input a sentence in any language and you will answer me in which language the sentence I wrote is in. Do not write any explanations or other words, just reply with the language name\"\n",
    "human_template_lang_detection = \"Sentence: {source_sentence}\"\n",
    "\n",
    "system_prompt_lang_detection = SystemMessagePromptTemplate.from_template(system_template_lang_detection)\n",
    "human_prompt_lang_detection = HumanMessagePromptTemplate.from_template(human_template_lang_detection)\n",
    "lang_detection_prompt = ChatPromptTemplate.from_messages([system_prompt_lang_detection, human_prompt_lang_detection])\n",
    "\n",
    "lang_detection_chain = LLMChain(llm=llm, prompt=lang_detection_prompt)\n",
    "source_language = lang_detection_chain.run(source_sentence=\"उपकरण को वाईफ़ाई से कनेक्ट करने के लिए कौन सी फ़्रीक्वेंसी राउटर समर्थित है?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "system_template_translation = \"You are a good Translator. Translate this sentence from {source_language} to English. Do not write any other words, just reply with the translated sentence.\"\n",
    "human_template_translation = \"Sentence: {source_sentence}\"\n",
    "\n",
    "system_prompt_translation = SystemMessagePromptTemplate.from_template(system_template_translation)\n",
    "human_prompt_translation = HumanMessagePromptTemplate.from_template(human_template_translation)\n",
    "translation_prompt = ChatPromptTemplate.from_messages([system_prompt_translation, human_prompt_translation])\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)\n",
    "target_sentence = translation_chain.run(source_language=source_language,source_sentence=\"उपकरण को वाईफ़ाई से कनेक्ट करने के लिए कौन सी फ़्रीक्वेंसी राउटर समर्थित है?\")\n",
    "target_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbcd3f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d444130-860e-4ffd-82a8-d9a96192f8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a0046e-d56f-49cc-835b-1e1130aeeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = 'NAGATO[Nagato] never changes, does she?'\n",
    "trn = 'See? \"13[Tsuruya-san] is totally fine!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f8d984-2bcc-4a95-8081-0bdbbc9ae284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'See? Tsuruya-san is totally fine!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn = re.sub(\"\\w+\\[\", \"\", trn)\n",
    "trn = re.sub(\"\\]\", \"\", trn)\n",
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ce9d16-5167-4714-854e-d2feb2b2aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(trn):\n",
    "    trn = re.sub(\"\\w+\\[\", \"\", trn)\n",
    "    trn = re.sub(\"\\]\", \"\", trn)\n",
    "    trn = re.sub(\"\\[\", \"\", trn)\n",
    "    trn = re.sub(\"'\", \"\", trn)\n",
    "    trn = re.sub('\"', \"\", trn)\n",
    "    return trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44864968-21bd-44e3-b79a-6ac6c1fc5420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'See? Tsuruya-san is totally fine!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74fed0-479f-4cc8-a5f9-2f44fcf1ac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
